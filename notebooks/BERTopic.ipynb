{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/garethsmith/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic import BERTopic\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_DIR = \"../data/processed\"\n",
    "\n",
    "FILENAME = \"twitter_airline_sentiment_cleaned_emoji_urls_html_symbols@#_quotes_currency_whitespace\"\n",
    "\n",
    "EMBEDDING_MPNET = \"twitter_airline_sentiment_cleaned_emoji_urls_html_symbols@#_quotes_currency_whitespace_all-mpnet-base-v2.npy\"\n",
    "\n",
    "EMBEDDING_TWHINBERT = \"twitter_airline_sentiment_cleaned_emoji_urls_html_symbols@#_quotes_currency_whitespace_twhin-bert-base.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "embeddings_mpnet = np.load(f\"{READ_DIR}/{EMBEDDING_MPNET}\")\n",
    "embeddings_twhinbert = np.load(f\"{READ_DIR}/{EMBEDDING_TWHINBERT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text data\n",
    "df = pd.read_csv(f\"{READ_DIR}/{FILENAME}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for UMAP\n",
    "n_neighbors = 15\n",
    "n_components = 5\n",
    "min_dist = 0.1\n",
    "metric_umap = \"cosine\"\n",
    "random_state = 0\n",
    "\n",
    "# UMAP model\n",
    "reducer = UMAP(\n",
    "    n_neighbors=n_neighbors,\n",
    "    n_components=n_components,\n",
    "    min_dist=min_dist,\n",
    "    metric=metric_umap,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "# Parameters for HDBScan\n",
    "min_cluster_size = 15\n",
    "min_samples = 5\n",
    "metric_hdbscan = \"euclidean\"\n",
    "cluster_selection_method = \"eom\"\n",
    "\n",
    "# HDBScan model\n",
    "clusterer = HDBSCAN(\n",
    "    min_cluster_size=min_cluster_size,\n",
    "    min_samples=min_samples,\n",
    "    metric=metric_hdbscan,\n",
    "    cluster_selection_method=cluster_selection_method,\n",
    "    prediction_data=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bertmodel(ngram_range, umap_model, hdbscan_model):\n",
    "    # Convert a collection of text documents to a matrix of token counts:\n",
    "    vectorizer = CountVectorizer(\n",
    "        stop_words=stopwords.words(\"english\"),\n",
    "        tokenizer=TweetTokenizer().tokenize,\n",
    "        token_pattern=None,\n",
    "        ngram_range=ngram_range,\n",
    "    )\n",
    "\n",
    "    # Fit BERTopic model with customisation:\n",
    "    topic_model = BERTopic(\n",
    "        vectorizer_model=vectorizer, umap_model=umap_model, hdbscan_model=hdbscan_model\n",
    "    )\n",
    "\n",
    "    return topic_model\n",
    "\n",
    "def get_topics_probs(model, docs, embeddings):\n",
    "    topics, probs = model.fit_transform(\n",
    "    docs, embeddings=embeddings)\n",
    "    return topics, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lower and upper boundary of the range of n-values for different word n-grams\n",
    "# or char n-grams to be extracted:\n",
    "ngram_range = (1, 2)\n",
    "\n",
    "bertmodel = get_bertmodel(\n",
    "        ngram_range=ngram_range,\n",
    "        umap_model=reducer, \n",
    "        hdbscan_model=clusterer)\n",
    "\n",
    "topics_mpnet, probs_mpnet = get_topics_probs(model=bertmodel,\n",
    "                 docs=list(df.clean_text),\n",
    "                 embeddings=embeddings_mpnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_bert(docs, embeddings, ngram_range, umap_model, hdbscan_model):\n",
    "    bertmodel = get_bertmodel(\n",
    "        ngram_range=ngram_range,\n",
    "        umap_model=reducer, \n",
    "        hdbscan_model=clusterer)\n",
    "    \n",
    "    topics, probs = get_topics_probs(model=bertmodel,\n",
    "                 docs=docs,\n",
    "                 embeddings=embeddings)\n",
    "    \n",
    "    return bertmodel, topics, probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertmodel_mpnet, topics_mpnet, probs_mpnet = fit_bert(docs=list(df.clean_text),\n",
    "    embeddings=embeddings_mpnet,\n",
    "        ngram_range=ngram_range, \n",
    "        umap_model=reducer, \n",
    "        hdbscan_model=clusterer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>7039</td>\n",
       "      <td>-1_flight_get_cancelled_thanks</td>\n",
       "      <td>[flight, get, cancelled, thanks, plane, im, us...</td>\n",
       "      <td>[about time! Thank you!, too Late Flight now, ...</td>\n",
       "      <td>48.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1061</td>\n",
       "      <td>0_bag_luggage_bags_baggage</td>\n",
       "      <td>[bag, luggage, bags, baggage, lost, claim, lef...</td>\n",
       "      <td>[Really... .you charge me $25 to check a bag a...</td>\n",
       "      <td>7.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>362</td>\n",
       "      <td>1_hold_call_phone_minutes</td>\n",
       "      <td>[hold, call, phone, minutes, hours, hung, hour...</td>\n",
       "      <td>[Was put on hold for 5.5 hrs then got a call b...</td>\n",
       "      <td>2.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>274</td>\n",
       "      <td>2_great_crew_great flight_attendant</td>\n",
       "      <td>[great, crew, great flight, attendant, thanks,...</td>\n",
       "      <td>[Great flight, as always! Thank you to the gre...</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>184</td>\n",
       "      <td>3_hold_cancelled_cancelled flightled_flightled</td>\n",
       "      <td>[hold, cancelled, cancelled flightled, flightl...</td>\n",
       "      <td>[been on hold for an hour. I need to rebook my...</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>119</td>\n",
       "      <td>15</td>\n",
       "      <td>119_apply_team job_job opening_recruiting</td>\n",
       "      <td>[apply, team job, job opening, recruiting, isi...</td>\n",
       "      <td>[i hope i get the opportunity to join the team...</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>120</td>\n",
       "      <td>15</td>\n",
       "      <td>120_connection_phl_help delayed_miss</td>\n",
       "      <td>[connection, phl, help delayed, miss, layover,...</td>\n",
       "      <td>[can you help me with a delayed flight as im g...</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>121</td>\n",
       "      <td>15</td>\n",
       "      <td>121_credit_purchased_refunded_receipt</td>\n",
       "      <td>[credit, purchased, refunded, receipt, yr, dat...</td>\n",
       "      <td>[- He Cancelled Flightled a flight &amp; was given...</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>122</td>\n",
       "      <td>15</td>\n",
       "      <td>122_worst experience_experience ever_worst_eve...</td>\n",
       "      <td>[worst experience, experience ever, worst, eve...</td>\n",
       "      <td>[this has to be the absolute WORST EXPERIENCE ...</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>123</td>\n",
       "      <td>15</td>\n",
       "      <td>123_departs enroute_enroute_departs_following ...</td>\n",
       "      <td>[departs enroute, enroute, departs, following ...</td>\n",
       "      <td>[Flight 3744 (N284WN) departs enroute to, Flig...</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic  Count                                               Name  \\\n",
       "0       -1   7039                     -1_flight_get_cancelled_thanks   \n",
       "1        0   1061                         0_bag_luggage_bags_baggage   \n",
       "2        1    362                          1_hold_call_phone_minutes   \n",
       "3        2    274                2_great_crew_great flight_attendant   \n",
       "4        3    184     3_hold_cancelled_cancelled flightled_flightled   \n",
       "..     ...    ...                                                ...   \n",
       "120    119     15          119_apply_team job_job opening_recruiting   \n",
       "121    120     15               120_connection_phl_help delayed_miss   \n",
       "122    121     15              121_credit_purchased_refunded_receipt   \n",
       "123    122     15  122_worst experience_experience ever_worst_eve...   \n",
       "124    123     15  123_departs enroute_enroute_departs_following ...   \n",
       "\n",
       "                                        Representation  \\\n",
       "0    [flight, get, cancelled, thanks, plane, im, us...   \n",
       "1    [bag, luggage, bags, baggage, lost, claim, lef...   \n",
       "2    [hold, call, phone, minutes, hours, hung, hour...   \n",
       "3    [great, crew, great flight, attendant, thanks,...   \n",
       "4    [hold, cancelled, cancelled flightled, flightl...   \n",
       "..                                                 ...   \n",
       "120  [apply, team job, job opening, recruiting, isi...   \n",
       "121  [connection, phl, help delayed, miss, layover,...   \n",
       "122  [credit, purchased, refunded, receipt, yr, dat...   \n",
       "123  [worst experience, experience ever, worst, eve...   \n",
       "124  [departs enroute, enroute, departs, following ...   \n",
       "\n",
       "                                   Representative_Docs  Percentage  \n",
       "0    [about time! Thank you!, too Late Flight now, ...       48.79  \n",
       "1    [Really... .you charge me $25 to check a bag a...        7.35  \n",
       "2    [Was put on hold for 5.5 hrs then got a call b...        2.51  \n",
       "3    [Great flight, as always! Thank you to the gre...        1.90  \n",
       "4    [been on hold for an hour. I need to rebook my...        1.28  \n",
       "..                                                 ...         ...  \n",
       "120  [i hope i get the opportunity to join the team...        0.10  \n",
       "121  [can you help me with a delayed flight as im g...        0.10  \n",
       "122  [- He Cancelled Flightled a flight & was given...        0.10  \n",
       "123  [this has to be the absolute WORST EXPERIENCE ...        0.10  \n",
       "124  [Flight 3744 (N284WN) departs enroute to, Flig...        0.10  \n",
       "\n",
       "[125 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bertopics = bertmodel.get_topic_info()\n",
    "print(\"Number of topics: {}\".format( len(df_bertopics)))\n",
    "df_bertopics['Percentage'] = round(df_bertopics['Count']/df_bertopics['Count'].sum() * 100,2)\n",
    "df_bertopics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = topic_model_bad.visualize_barchart(top_n_topics = 10)\n",
    "fig2.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
